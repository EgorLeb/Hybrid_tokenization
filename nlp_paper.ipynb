{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFpH3JEbwKxa"
      },
      "outputs": [],
      "source": [
        "# !zip -r phrase_tokenizer phrase_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0e9cbRGm9aw",
        "outputId": "c2c1e926-5aa2-458f-edf7-a3c05601b220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdqUd6pCQ1dv",
        "outputId": "26cc7d4a-f59f-400c-e660-0e6e954f0db0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "from datasets import Dataset, load_dataset, DatasetDict\n",
        "from transformers import pipeline, set_seed\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "import os\n",
        "import string\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hjrusWcw6tx"
      },
      "source": [
        "## Load and preprocess bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKucZfx4Yleo",
        "outputId": "a7ef4c7a-ff99-4d44-fc1b-50dc18d7c02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/toddcook/bert-english-uncased-bigrams/versions/3\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"toddcook/bert-english-uncased-bigrams\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCmx3KDnY5oL",
        "outputId": "136c3814-8d6e-4879-e7b1-873b3a08c874"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "251195it [00:00, 391722.64it/s]\n"
          ]
        }
      ],
      "source": [
        "filename = 'bert.eng.uncased.bigrams.csv'\n",
        "\n",
        "stopwords_set = set(stopwords.words('english'))\n",
        "punctuation_set = set(string.punctuation)\n",
        "\n",
        "def is_valid_token(token):\n",
        "    not_alphas = sum([not char.isalpha() for char in token])\n",
        "    return token.lower() not in stopwords_set and token not in punctuation_set and not_alphas == 0 and not token.isdigit()\n",
        "\n",
        "\n",
        "input_file_path = os.path.join(path, filename)\n",
        "\n",
        "output_file_path = os.path.join('valid_bigrams.csv')\n",
        "\n",
        "with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
        "    outfile.write(\"bigram_1,bigram_2,count\\n\")\n",
        "\n",
        "    for idx, line in tqdm(enumerate(infile)):\n",
        "        parts = line.strip().split()\n",
        "\n",
        "        if idx == 0 or \"'\" in parts[0]:\n",
        "          continue\n",
        "\n",
        "        if len(parts) == 3:\n",
        "            bigram_1, bigram_2, count = parts\n",
        "\n",
        "            if int(count) < 1000 :\n",
        "              break\n",
        "\n",
        "            if is_valid_token(bigram_1) and is_valid_token(bigram_2):\n",
        "                outfile.write(f\"{bigram_1},{bigram_2},{count}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OIJI7au6h4iK",
        "outputId": "304102d8-e17d-434b-a237-a62e66d56595"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 39246,\n  \"fields\": [\n    {\n      \"column\": \"bigram_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6860,\n        \"samples\": [\n          \"sooner\",\n          \"bedside\",\n          \"adams\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bigram_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7644,\n        \"samples\": [\n          \"lock\",\n          \"vacant\",\n          \"flicked\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9514,\n        \"min\": 1000,\n        \"max\": 1026737,\n        \"num_unique_values\": 7528,\n        \"samples\": [\n          2651,\n          13643,\n          6759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ed5cc4f6-e394-4b50-a9cd-7efe65387f2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bigram_1</th>\n",
              "      <th>bigram_2</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>united</td>\n",
              "      <td>states</td>\n",
              "      <td>1026737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new</td>\n",
              "      <td>york</td>\n",
              "      <td>791984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>world</td>\n",
              "      <td>war</td>\n",
              "      <td>378418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>first</td>\n",
              "      <td>time</td>\n",
              "      <td>298847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>also</td>\n",
              "      <td>known</td>\n",
              "      <td>228084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39241</th>\n",
              "      <td>inflicted</td>\n",
              "      <td>upon</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39242</th>\n",
              "      <td>mind</td>\n",
              "      <td>telling</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39243</th>\n",
              "      <td>toured</td>\n",
              "      <td>throughout</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39244</th>\n",
              "      <td>la</td>\n",
              "      <td>fontaine</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39245</th>\n",
              "      <td>new</td>\n",
              "      <td>blood</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39246 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed5cc4f6-e394-4b50-a9cd-7efe65387f2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed5cc4f6-e394-4b50-a9cd-7efe65387f2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed5cc4f6-e394-4b50-a9cd-7efe65387f2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc324266-18cd-4251-8698-af90d96ee974\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc324266-18cd-4251-8698-af90d96ee974')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc324266-18cd-4251-8698-af90d96ee974 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        bigram_1    bigram_2    count\n",
              "0         united      states  1026737\n",
              "1            new        york   791984\n",
              "2          world         war   378418\n",
              "3          first        time   298847\n",
              "4           also       known   228084\n",
              "...          ...         ...      ...\n",
              "39241  inflicted        upon     1000\n",
              "39242       mind     telling     1000\n",
              "39243     toured  throughout     1000\n",
              "39244         la    fontaine     1000\n",
              "39245        new       blood     1000\n",
              "\n",
              "[39246 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(output_file_path, on_bad_lines='skip')\n",
        "bigram_set = set(df.apply(lambda row: ' '.join([row['bigram_1'], row['bigram_2']]), axis=1))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Zh_X5eYkeD_R",
        "outputId": "47e8eec9-1403-4830-f202-4ea0d178c87f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df[(df['bigram_1'] == 'grow') & (df['bigram_2'] == \\\"old\\\")]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"bigram_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"grow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bigram_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"old\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1498,\n        \"max\": 1498,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1498\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-54f6666c-f3d3-4ce7-a755-b467dc572c7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bigram_1</th>\n",
              "      <th>bigram_2</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23639</th>\n",
              "      <td>grow</td>\n",
              "      <td>old</td>\n",
              "      <td>1498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54f6666c-f3d3-4ce7-a755-b467dc572c7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54f6666c-f3d3-4ce7-a755-b467dc572c7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54f6666c-f3d3-4ce7-a755-b467dc572c7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      bigram_1 bigram_2  count\n",
              "23639     grow      old   1498"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[(df['bigram_1'] == 'grow') & (df['bigram_2'] == \"old\")]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzK63ycTxLpl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-dUT2XGxGR_"
      },
      "source": [
        "## Create custom tokenizer\n",
        "\n",
        "A tokenizer splits text into phrases (is present at vocabulary) or words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KVHS-Fwfz_F"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizer\n",
        "from typing import Dict, List, Optional, Union\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "class PhraseTokenizer(PreTrainedTokenizer):\n",
        "    def __init__(self, phrase_set, **kwargs):\n",
        "\n",
        "        self.split_special_tokens = False\n",
        "        self.verbose = False\n",
        "\n",
        "        self.unk_token=\"[UNK]\"\n",
        "        self.sep_token=\"[SEP]\"\n",
        "        self.pad_token=\"[PAD]\"\n",
        "        self.cls_token=\"[CLS]\"\n",
        "        self.mask_token=\"[MASK]\"\n",
        "\n",
        "        self.max_phrase_length = 2    #  !!!!!may change later!!!!!!\n",
        "        self.phrase_set = phrase_set\n",
        "        self.vocab = self._build_vocab()\n",
        "        self.id_to_token = {v: k for k, v in self.vocab.items()}\n",
        "\n",
        "        super().__init__(\n",
        "            unk_token=\"[UNK]\",\n",
        "            sep_token=\"[SEP]\",\n",
        "            pad_token=\"[PAD]\",\n",
        "            cls_token=\"[CLS]\",\n",
        "            mask_token=\"[MASK]\",\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "\n",
        "    def _build_vocab(self) -> Dict[str, int]:\n",
        "        vocab = {}\n",
        "        idx = 0\n",
        "\n",
        "        special_tokens = [\n",
        "            self.unk_token, self.sep_token, self.pad_token, self.cls_token, self.mask_token\n",
        "        ]\n",
        "        for token in special_tokens:\n",
        "            vocab[token] = idx\n",
        "            idx += 1\n",
        "\n",
        "        for phrase in self.phrase_set:\n",
        "            if phrase not in vocab:\n",
        "                vocab[phrase] = idx\n",
        "                idx += 1\n",
        "\n",
        "        return vocab\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        lowercase_words = word_tokenize(text.lower())\n",
        "        original_words = word_tokenize(text)\n",
        "\n",
        "        tokens = []\n",
        "        i = 0\n",
        "\n",
        "        while i < len(lowercase_words):\n",
        "            # match the longest possible phrase\n",
        "            max_phrase_length = min(self.max_phrase_length, len(lowercase_words) - i)\n",
        "            for j in range(max_phrase_length, 0, -1):\n",
        "                phrase = \" \".join(lowercase_words[i:i+j])\n",
        "                if phrase in self.vocab:\n",
        "                    original_phrase = \" \".join(original_words[i:i+j])\n",
        "                    tokens.append(original_phrase)\n",
        "                    i += j\n",
        "                    break\n",
        "            else:\n",
        "                # add as a single token\n",
        "                tokens.append(original_words[i])\n",
        "                i += 1\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        return self.vocab.get(token, self.vocab[\"[UNK]\"])\n",
        "\n",
        "    def _convert_id_to_token(self, index):\n",
        "        return self.id_to_token.get(index, \"[UNK]\")\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return self.vocab\n",
        "\n",
        "    def save_pretrained(self, save_directory: str, **kwargs):\n",
        "        if not os.path.isdir(save_directory):\n",
        "            os.mkdir(save_directory)\n",
        "        vocab_file = os.path.join(save_directory, \"vocab.txt\")\n",
        "        with open(vocab_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            for token in self.vocab:\n",
        "                f.write(token + \"\\n\")\n",
        "\n",
        "        config = {\n",
        "            \"unk_token\": self.unk_token,\n",
        "            \"sep_token\": self.sep_token,\n",
        "            \"pad_token\": self.pad_token,\n",
        "            \"cls_token\": self.cls_token,\n",
        "            \"mask_token\": self.mask_token,\n",
        "            \"max_phrase_length\": self.max_phrase_length,\n",
        "            \"phrase_set\": list(self.phrase_set)\n",
        "        }\n",
        "        config_file = os.path.join(save_directory, \"tokenizer_config.json\")\n",
        "        with open(config_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, save_directory: str, **kwargs):\n",
        "        config_file = os.path.join(save_directory, \"tokenizer_config.json\")\n",
        "        with open(config_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        # Load vocabulary (preserve order!)\n",
        "        vocab_file = os.path.join(save_directory, \"vocab.txt\")\n",
        "        with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            # Read phrases in order (skip special tokens already in config)\n",
        "            phrase_set = [line.strip() for line in f if line.strip() not in {\n",
        "                config[\"unk_token\"], config[\"sep_token\"],\n",
        "                config[\"pad_token\"], config[\"cls_token\"],\n",
        "                config[\"mask_token\"]\n",
        "            }]\n",
        "\n",
        "        return cls(\n",
        "            phrase_set=set(phrase_set),\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        text: Union[str, List[str]],\n",
        "        text_pair: Optional[Union[str, List[str]]] = None,\n",
        "        add_special_tokens: bool = False,\n",
        "        padding: Union[bool, str] = False,\n",
        "        truncation: Union[bool, str] = False,\n",
        "        max_length: Optional[int] = None,\n",
        "        return_tensors: Optional[str] = None,\n",
        "        **kwargs\n",
        "    ) -> Dict[str, List[int]]:\n",
        "        tokens = self._tokenize(text)\n",
        "\n",
        "        if add_special_tokens:\n",
        "            tokens = [self.cls_token] + tokens + [self.sep_token]\n",
        "\n",
        "        input_ids = [self._convert_token_to_id(token) for token in tokens]\n",
        "\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        if padding:\n",
        "            max_len = max_length if max_length else self.model_max_length\n",
        "            if len(input_ids) < max_len:\n",
        "                pad_length = max_len - len(input_ids)\n",
        "                input_ids += [self.pad_token_id] * pad_length\n",
        "                attention_mask += [0] * pad_length\n",
        "            elif truncation and len(input_ids) > max_len:\n",
        "                input_ids = input_ids[:max_len]\n",
        "                attention_mask = attention_mask[:max_len]\n",
        "\n",
        "        if return_tensors == \"pt\":\n",
        "            input_ids = torch.tensor([input_ids])\n",
        "            attention_mask = torch.tensor([attention_mask])\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def pad_token_id(self) -> int:\n",
        "        return self.vocab[self.pad_token]\n",
        "\n",
        "    @property\n",
        "    def cls_token_id(self) -> int:\n",
        "        return self.vocab[self.cls_token]\n",
        "\n",
        "    @property\n",
        "    def sep_token_id(self) -> int:\n",
        "        return self.vocab[self.sep_token]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DooScHtUyBmt"
      },
      "source": [
        "Check how the tokenizer works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs8SaK_Lw3HR",
        "outputId": "738a2b76-2878-45b7-d866-72932754a4b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [0, 0, 0, 14622, 0, 0, 0, 0, 0, 0, 9751, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "{'input_ids': [0, 0, 0, 14622, 0, 0, 0, 0, 0, 0, 9751, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "['New York', 'is', 'a', 'big city', '.', 'Machine learning', 'is', 'a', 'part', 'of', 'artificial intelligence', '.']\n"
          ]
        }
      ],
      "source": [
        "text = \"New York is a big city. Machine learning is a part of artificial intelligence.\"\n",
        "\n",
        "custom_tokenizer = PhraseTokenizer(bigram_set)\n",
        "tokenized_text = custom_tokenizer(text)\n",
        "custom_tokenizer.save_pretrained(\"phrase_tokenizer\")\n",
        "\n",
        "phrase_tok = PhraseTokenizer.from_pretrained(\"phrase_tokenizer\")\n",
        "tokenized_text_1 = phrase_tok(text)\n",
        "\n",
        "print(tokenized_text)\n",
        "print(tokenized_text_1)\n",
        "print(custom_tokenizer.tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAANSdIIw273"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jYVKjqavtRh"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "base_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
        "QwenModel = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
        "\n",
        "embeddings = QwenModel.get_input_embeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG-iejFOztD1",
        "outputId": "85768c55-34fc-4e97-fe9e-7cf7d837c69b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['New', 'ĠYork', 'Ġis', 'Ġa', 'Ġbig', 'Ġcity', '.', 'ĠMachine', 'Ġlearning', 'Ġis', 'Ġa', 'Ġpart', 'Ġof', 'Ġartificial', 'Ġintelligence', '.']\n"
          ]
        }
      ],
      "source": [
        "print(base_tokenizer.tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnknf0uSjN3C"
      },
      "outputs": [],
      "source": [
        "def get_embedding_for_token(token, base_tokenizer, embeddings):\n",
        "    \"\"\"\n",
        "    Get the embedding for a token using the pre-trained model's tokenizer and embeddings.\n",
        "    If the token is not in the vocabulary, use the mean of its subword embeddings.\n",
        "    \"\"\"\n",
        "    subwords = base_tokenizer.tokenize(token)\n",
        "\n",
        "    if not subwords:\n",
        "        return torch.zeros(embeddings.embedding_dim)  #!!! change to rand!!!\n",
        "\n",
        "    subword_ids = base_tokenizer.convert_tokens_to_ids(subwords)\n",
        "    subword_embeddings = embeddings(torch.tensor(subword_ids))\n",
        "\n",
        "    return torch.mean(subword_embeddings, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbn0aqM3jNxi"
      },
      "outputs": [],
      "source": [
        "def get_embeddings_for_sequence(text, custom_tokenizer, base_tokenizer, embeddings):\n",
        "    \"\"\"\n",
        "    Get embeddings for a sequence of tokens using the pre-trained model's tokenizer and embeddings.\n",
        "    \"\"\"\n",
        "    custom_tokenized_tokens = custom_tokenizer.tokenize(text)\n",
        "    sequence_embeddings = []\n",
        "\n",
        "    for token in custom_tokenized_tokens:\n",
        "        embedding = get_embedding_for_token(token, base_tokenizer, embeddings)\n",
        "        sequence_embeddings.append(embedding[:][:3])\n",
        "\n",
        "    return torch.stack(sequence_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NFjWrnr4aFu"
      },
      "outputs": [],
      "source": [
        "sw = base_tokenizer.tokenize(\"New York is\")\n",
        "sw_i = base_tokenizer.convert_tokens_to_ids(sw)\n",
        "sw_e = embeddings(torch.tensor(sw_i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTiQ0SZ7A-M5",
        "outputId": "25300f88-2297-4537-b0ac-886e0e7053b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['New', 'ĠYork', 'Ġis']\n"
          ]
        }
      ],
      "source": [
        "print(sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v4Cs9fH4tmS",
        "outputId": "36472d3b-33c2-424c-b347-300ae339b1b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.0176,  0.0114,  0.0320], grad_fn=<SliceBackward0>)\n",
            "tensor([-0.0087, -0.0189,  0.0021], grad_fn=<SliceBackward0>)\n",
            "tensor([ 0.0156, -0.0188,  0.0114], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(sw_e[0][:3])\n",
        "print(sw_e[1][:3])\n",
        "print(sw_e[2][:3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLYw6BivjNuu",
        "outputId": "6e8fe7a9-9e10-4a3e-cb92-bd82a6820947"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0131, -0.0038,  0.0170],\n",
              "        [-0.0221, -0.0322,  0.0106]], grad_fn=<StackBackward0>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_embeddings_for_sequence('New York is', custom_tokenizer, base_tokenizer, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePpX_4P3jNr8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krixDFxvjNox"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvV75TvbHBvb"
      },
      "source": [
        "### Load dataset for summarization fune tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7f4cW3839cC",
        "outputId": "18a92936-2460-44f6-b5fa-6d2576e5b22e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW2zgw-3mRVt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxhdckfuBETW"
      },
      "source": [
        "## Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDhJB2CMmRS_"
      },
      "outputs": [],
      "source": [
        "class QwenWithPhrases(QwenModel.__class__):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.model = AutoModelForCausalLM.from_config(config)\n",
        "        self.subword_embed = self.model.get_input_embeddings()\n",
        "        self.phrase_projector = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        subword_ids: torch.Tensor,\n",
        "        phrase_embeddings: torch.Tensor,\n",
        "        attention_mask: torch.Tensor\n",
        "    ):\n",
        "        subword_embeds = self.subword_embed(subword_ids)\n",
        "        phrase_embeds = self.phrase_projector(phrase_embeddings)\n",
        "\n",
        "        fused_embeds = 0.7 * subword_embeds + 0.3 * phrase_embeds\n",
        "\n",
        "        outputs = self.model(\n",
        "            inputs_embeds=fused_embeds,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VnS-aMH4XoF"
      },
      "outputs": [],
      "source": [
        "###### TEMP  ######\n",
        "\n",
        "short_dataset = DatasetDict()\n",
        "for s in dataset:\n",
        "  short_dataset[s] = dataset[s].select(range(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3Ll37PV-LWp",
        "outputId": "1a559767-8c6e-4e93-a6a2-f078ffc50cf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0096, -0.0073,  0.0090],\n",
              "        [-0.0325, -0.0471,  0.0238],\n",
              "        [ 0.0037,  0.0154, -0.0240],\n",
              "        ...,\n",
              "        [ 0.0177, -0.0269, -0.0025],\n",
              "        [ 0.0075,  0.0049, -0.0067],\n",
              "        [-0.0371, -0.0261,  0.0200]], grad_fn=<StackBackward0>)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = dataset['train']['article'][0]\n",
        "get_embeddings_for_sequence(text=text, custom_tokenizer=custom_tokenizer, base_tokenizer=base_tokenizer, embeddings=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "e177bc27c4774a2bb571fb9592be905f",
            "872c3f3072cb48d6838ebb12ea4099a2",
            "305870d28ed24d3e901bf2c2b2519913",
            "787336c80be849d2a20a54482b0b5cc8",
            "9bc64b56790740f5a6ad74a52966191e",
            "82b27491408b43d38ff6528ebab4f5f5",
            "8e4b5b6a39544d41bb702d11e7b9f1da",
            "8d4c21ce12a2421dae27c8e75d94c1f6",
            "5fd3f259ac5b4cf5ad67c88bba6147bf",
            "cbe5f8b91d9d4ea6baf24b4a80400200",
            "f8d00625877e4f2990e6042988243296",
            "3208a9f69180474bb40d67dbfc4b5d9a",
            "da48f9d613f24ed3accf438fdf7eb399",
            "15921f69348a4705ae60832d1661cc59",
            "68a1bb05b9e543578dfa2bc869878cd3",
            "abbe0a9499034cc28d1a119dee3b462a",
            "2fbbcfaa08734b5c89119d3626f48b2b",
            "e414f426f2da498faff1c0e1d1c1ad10",
            "b62c0716702a47178d509d3d0d4a429b",
            "7052bc80032748509286c2caace5ae80",
            "ec9710eef9834dad9e8e74c6dcf2f6b7",
            "4b0cd0a5db594b1e99f6ce93b372d5c0",
            "202e1a2e48864abb986bace15f2105d4",
            "69735aa687c54b21b2f5a08c0cd69a40",
            "66e36f8df9f34d869e80450668f69a6e",
            "b3a61c68405248d38f26558b1463e2d8",
            "baf6318a7af74ad6b4d7ef1f6966242f",
            "41b5c19ed53446ebabcb93145ebc3fa5",
            "e307ee5570b04e09a652ed3ac4f86918",
            "bf126a91cfea45898c773e6bddea424e",
            "75b001710b7543bca66f0e1f97f988d6",
            "cbb8797b60e84ed98a8963601e8f4776",
            "77526cd851d14415aa660f73b86d2de9"
          ]
        },
        "id": "mgumQ3HhmRP2",
        "outputId": "22322b9d-7649-46ac-de41-24249bd4b140"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parameter 'function'=<function preprocess_function at 0x79d322b8b9c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "WARNING:datasets.fingerprint:Parameter 'function'=<function preprocess_function at 0x79d322b8b9c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e177bc27c4774a2bb571fb9592be905f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3208a9f69180474bb40d67dbfc4b5d9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "202e1a2e48864abb986bace15f2105d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "\n",
        "  ### embed articles ###\n",
        "    model_inputs = base_tokenizer(\n",
        "        examples[\"article\"],\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "  ### phrase embed articles ###\n",
        "    phrase_embeddings = []\n",
        "    max_phrase_length = 512\n",
        "\n",
        "    for article in examples[\"article\"]:\n",
        "        ph_embeddings = get_embeddings_for_sequence(\n",
        "            text=article,\n",
        "            custom_tokenizer=custom_tokenizer,\n",
        "            base_tokenizer=base_tokenizer,\n",
        "            embeddings=embeddings\n",
        "        )\n",
        "\n",
        "        if ph_embeddings.shape[0] < max_phrase_length:\n",
        "            padding_length = max_phrase_length - ph_embeddings.shape[0]\n",
        "            ph_embeddings = F.pad(ph_embeddings, (0, 0, 0, padding_length))  # Pad along the sequence dimension\n",
        "        else:\n",
        "            ph_embeddings = ph_embeddings[:max_phrase_length, :]  # Truncate if necessary\n",
        "\n",
        "        phrase_embeddings.append(ph_embeddings)\n",
        "\n",
        "    phrase_embeddings = torch.stack(phrase_embeddings)\n",
        "\n",
        "    model_inputs[\"phrase_embeddings\"] = phrase_embeddings\n",
        "\n",
        "    ### embed highlights ###\n",
        "    with base_tokenizer.as_target_tokenizer():\n",
        "        labels = base_tokenizer(\n",
        "            examples[\"highlights\"],\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "\n",
        "    ### phrase embed highlights ###\n",
        "    phrase_embedded_highlights = []\n",
        "    max_phrase_length = 128\n",
        "\n",
        "    for highlight in examples[\"highlights\"]:\n",
        "        ph_embeddings = get_embeddings_for_sequence(\n",
        "            text=highlight,\n",
        "            custom_tokenizer=custom_tokenizer,\n",
        "            base_tokenizer=base_tokenizer,\n",
        "            embeddings=embeddings\n",
        "        )\n",
        "\n",
        "        if ph_embeddings.shape[0] < max_phrase_length:\n",
        "            padding_length = max_phrase_length - ph_embeddings.shape[0]\n",
        "            ph_embeddings = F.pad(ph_embeddings, (0, 0, 0, padding_length))\n",
        "        else:\n",
        "            ph_embeddings = ph_embeddings[:max_phrase_length, :]\n",
        "\n",
        "        phrase_embedded_highlights.append(ph_embeddings)\n",
        "\n",
        "    phrase_embedded_highlights = torch.stack(phrase_embedded_highlights)\n",
        "\n",
        "    model_inputs[\"phrase_labels\"] = phrase_embeddings\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = short_dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCLw6w0RLtqF",
        "outputId": "36500df5-e52c-40e3-d42c-a953d2684086"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'phrase_embeddings', 'labels', 'phrase_labels'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'phrase_embeddings', 'labels', 'phrase_labels'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'phrase_embeddings', 'labels', 'phrase_labels'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IUMnZp33mfx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VLw_7dSmRMw"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "config = AutoConfig.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
        "\n",
        "model = QwenWithPhrases(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1V-0I1zv7Ab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWXA_YHTv65z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDo7EvYOMrNZ"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "e1cce9cea42b4f5ab74f3ebc98c1b251"
          ]
        },
        "id": "Wt41zxUJkv88",
        "outputId": "be14bc91-2c88-48f4-c5be-2b03613bb457"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1cce9cea42b4f5ab74f3ebc98c1b251",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ImportError",
          "evalue": "To be able to use evaluate-metric/rouge, you need to install the following dependencies['rouge_score'] using 'pip install rouge_score' for instance'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-5ddb60cfe5bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rouge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \"\"\"\n\u001b[1;32m    747\u001b[0m     \u001b[0mdownload_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREUSE_DATASET_IF_EXISTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     evaluation_module = evaluation_module_factory(\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m             raise FileNotFoundError(\n\u001b[1;32m    682\u001b[0m                 \u001b[0;34mf\"Couldn't find a module script at {relative_to_absolute_path(combined_path)}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                 \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                                 \u001b[0mdynamic_modules_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_modules_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m                             ).get_module()\n\u001b[0m\u001b[1;32m    640\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mimports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_imports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         local_imports = _download_additional_modules(\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_hub_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36m_download_additional_modules\u001b[0;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mneeds_to_be_installed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_import_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibrary_import_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mneeds_to_be_installed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;34mf\"To be able to use {name}, you need to install the following dependencies\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;34mf\"{[lib_name for lib_name, lib_path in needs_to_be_installed]} using 'pip install \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: To be able to use evaluate-metric/rouge, you need to install the following dependencies['rouge_score'] using 'pip install rouge_score' for instance'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBKNx7Ptkv6U"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMuFcroUkv3i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB3SU0I6kv05"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqasawmZkvyD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu7pelOdkvu3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMXKvEkFkvqj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoX7kvc_msTd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15921f69348a4705ae60832d1661cc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b62c0716702a47178d509d3d0d4a429b",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7052bc80032748509286c2caace5ae80",
            "value": 10
          }
        },
        "202e1a2e48864abb986bace15f2105d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69735aa687c54b21b2f5a08c0cd69a40",
              "IPY_MODEL_66e36f8df9f34d869e80450668f69a6e",
              "IPY_MODEL_b3a61c68405248d38f26558b1463e2d8"
            ],
            "layout": "IPY_MODEL_baf6318a7af74ad6b4d7ef1f6966242f"
          }
        },
        "2fbbcfaa08734b5c89119d3626f48b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305870d28ed24d3e901bf2c2b2519913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d4c21ce12a2421dae27c8e75d94c1f6",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fd3f259ac5b4cf5ad67c88bba6147bf",
            "value": 10
          }
        },
        "3208a9f69180474bb40d67dbfc4b5d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da48f9d613f24ed3accf438fdf7eb399",
              "IPY_MODEL_15921f69348a4705ae60832d1661cc59",
              "IPY_MODEL_68a1bb05b9e543578dfa2bc869878cd3"
            ],
            "layout": "IPY_MODEL_abbe0a9499034cc28d1a119dee3b462a"
          }
        },
        "41b5c19ed53446ebabcb93145ebc3fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0cd0a5db594b1e99f6ce93b372d5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fd3f259ac5b4cf5ad67c88bba6147bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66e36f8df9f34d869e80450668f69a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf126a91cfea45898c773e6bddea424e",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75b001710b7543bca66f0e1f97f988d6",
            "value": 10
          }
        },
        "68a1bb05b9e543578dfa2bc869878cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9710eef9834dad9e8e74c6dcf2f6b7",
            "placeholder": "​",
            "style": "IPY_MODEL_4b0cd0a5db594b1e99f6ce93b372d5c0",
            "value": " 10/10 [00:02&lt;00:00,  4.45 examples/s]"
          }
        },
        "69735aa687c54b21b2f5a08c0cd69a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b5c19ed53446ebabcb93145ebc3fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_e307ee5570b04e09a652ed3ac4f86918",
            "value": "Map: 100%"
          }
        },
        "7052bc80032748509286c2caace5ae80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75b001710b7543bca66f0e1f97f988d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77526cd851d14415aa660f73b86d2de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787336c80be849d2a20a54482b0b5cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe5f8b91d9d4ea6baf24b4a80400200",
            "placeholder": "​",
            "style": "IPY_MODEL_f8d00625877e4f2990e6042988243296",
            "value": " 10/10 [00:02&lt;00:00,  3.86 examples/s]"
          }
        },
        "82b27491408b43d38ff6528ebab4f5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872c3f3072cb48d6838ebb12ea4099a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b27491408b43d38ff6528ebab4f5f5",
            "placeholder": "​",
            "style": "IPY_MODEL_8e4b5b6a39544d41bb702d11e7b9f1da",
            "value": "Map: 100%"
          }
        },
        "8d4c21ce12a2421dae27c8e75d94c1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4b5b6a39544d41bb702d11e7b9f1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bc64b56790740f5a6ad74a52966191e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbe0a9499034cc28d1a119dee3b462a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a61c68405248d38f26558b1463e2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb8797b60e84ed98a8963601e8f4776",
            "placeholder": "​",
            "style": "IPY_MODEL_77526cd851d14415aa660f73b86d2de9",
            "value": " 10/10 [00:03&lt;00:00,  2.91 examples/s]"
          }
        },
        "b62c0716702a47178d509d3d0d4a429b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf6318a7af74ad6b4d7ef1f6966242f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf126a91cfea45898c773e6bddea424e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb8797b60e84ed98a8963601e8f4776": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe5f8b91d9d4ea6baf24b4a80400200": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da48f9d613f24ed3accf438fdf7eb399": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fbbcfaa08734b5c89119d3626f48b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_e414f426f2da498faff1c0e1d1c1ad10",
            "value": "Map: 100%"
          }
        },
        "e177bc27c4774a2bb571fb9592be905f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_872c3f3072cb48d6838ebb12ea4099a2",
              "IPY_MODEL_305870d28ed24d3e901bf2c2b2519913",
              "IPY_MODEL_787336c80be849d2a20a54482b0b5cc8"
            ],
            "layout": "IPY_MODEL_9bc64b56790740f5a6ad74a52966191e"
          }
        },
        "e307ee5570b04e09a652ed3ac4f86918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e414f426f2da498faff1c0e1d1c1ad10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec9710eef9834dad9e8e74c6dcf2f6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d00625877e4f2990e6042988243296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}